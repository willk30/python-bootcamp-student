{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 3: From Data to Insights - Predictive Modeling with Scikit-learn\n",
    "\n",
    "**Python Module for Incoming ISE & OR PhD Students**  \n",
    "Instructor: Will Kirschenman | August 7, 2025 | 11:00 AM - 11:50 AM\n",
    "\n",
    "---\n",
    "\n",
    "## Welcome to Block 3! 🤖\n",
    "\n",
    "In Block 2, we wrestled our messy PhD student data into submission and emerged victorious with a clean dataset. Now comes the fun part: **making predictions!** \n",
    "\n",
    "Today we're entering the world of **machine learning** with Python's most popular ML library: **Scikit-learn**. By the end of this block, you'll be able to:\n",
    "\n",
    "- Build and train linear regression models\n",
    "- Evaluate model performance like a data scientist\n",
    "- Make predictions about PhD research productivity\n",
    "- Interpret results to gain actual insights\n",
    "- Understand what factors predict PhD success\n",
    "\n",
    "**Our Mission**: Use our cleaned PhD student dataset to build a model that predicts research productivity (papers published). We'll discover which factors matter most: Is it the coffee? The Hunt Library hours? The advisor meetings? Let's find out! ☕📚🎓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Package Installation & Setup\n",
    "# Run this cell ONLY if you encounter import errors\n",
    "# Most packages are pre-installed in Google Colab\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package_name):\n",
    "    \"\"\"Install a package using pip if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        print(f\"✅ {package_name} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"📦 Installing {package_name}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"✅ {package_name} installed successfully\")\n",
    "\n",
    "# Core packages used in this notebook (Block 3: Machine Learning)\n",
    "required_packages = [\n",
    "    'numpy',\n",
    "    'pandas', \n",
    "    'matplotlib',\n",
    "    'seaborn',\n",
    "    'scikit-learn',\n",
    "    'scipy',\n",
    "    'statsmodels'\n",
    "]\n",
    "\n",
    "print(\"🔍 Checking required packages for Block 3...\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n🎉 All packages ready! You can now run all cells without import errors.\")\n",
    "print(\"💡 Tip: In Google Colab, most packages are pre-installed, so you likely won't need to install anything!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Our ML Arsenal\n",
    "\n",
    "Let's import the tools we'll need. Google Colab has all these pre-installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning with Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set up pretty plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"🚀 Libraries imported successfully!\")\n",
    "print(f\"📊 Pandas version: {pd.__version__}\")\n",
    "print(f\"🤖 Scikit-learn imported and ready!\")\n",
    "print(f\"🎯 Let's build some models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Welcome to Machine Learning! 🎯\n",
    "\n",
    "## What is Machine Learning?\n",
    "\n",
    "Machine Learning is about **finding patterns in data** and using those patterns to **make predictions**. Think of it as teaching a computer to learn from experience, just like we do!\n",
    "\n",
    "### Types of Machine Learning:\n",
    "\n",
    "1. **Supervised Learning** 👨‍🏫\n",
    "   - We have input features (X) and target outcomes (y)\n",
    "   - Algorithm learns the relationship: X → y\n",
    "   - Examples: Predicting house prices, diagnosing diseases, forecasting demand\n",
    "\n",
    "2. **Unsupervised Learning** 🔍\n",
    "   - Only input features (X), no target outcomes\n",
    "   - Algorithm finds hidden patterns\n",
    "   - Examples: Customer segmentation, anomaly detection\n",
    "\n",
    "3. **Reinforcement Learning** 🎮\n",
    "   - Agent learns through trial and error\n",
    "   - Examples: Game playing, robotics\n",
    "\n",
    "**Today's Focus**: Supervised learning with **Linear Regression** - perfect for understanding relationships in research data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression: The Foundation of Prediction\n",
    "\n",
    "Linear regression finds the \"best line\" through your data points. It's like drawing a trend line, but with mathematical precision!\n",
    "\n",
    "**The Math** (don't worry, scikit-learn handles this!):\n",
    "```\n",
    "y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε\n",
    "```\n",
    "\n",
    "**In PhD Terms**:\n",
    "```\n",
    "Papers Published = Baseline + \n",
    "                   (Coffee Effect × Coffee Cups) + \n",
    "                   (Years Effect × Years in Program) + \n",
    "                   (Library Effect × Hunt Library Hours) + \n",
    "                   ... + Random Variation\n",
    "```\n",
    "\n",
    "**Why Linear Regression?**\n",
    "- 📊 **Interpretable**: We can understand what each factor contributes\n",
    "- 🚀 **Fast**: Trains quickly, makes predictions instantly\n",
    "- 🎯 **Baseline**: Great starting point for any prediction problem\n",
    "- 📈 **Robust**: Works well with many types of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meet Scikit-learn: Your ML Best Friend\n",
    "\n",
    "Scikit-learn follows a simple, consistent pattern:\n",
    "\n",
    "1. **Import** the algorithm\n",
    "2. **Create** a model instance\n",
    "3. **Fit** the model to training data\n",
    "4. **Predict** on new data\n",
    "5. **Evaluate** performance\n",
    "\n",
    "Let's see this in action with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example: Coffee consumption vs Papers published\n",
    "# (We'll use our real data soon!)\n",
    "\n",
    "# Create some sample data\n",
    "coffee_cups = np.array([2, 3, 4, 5, 6, 7, 8]).reshape(-1, 1)  # reshape for sklearn which expects 2D array for features\n",
    "papers = np.array([1, 2, 2, 3, 4, 5, 6])\n",
    "\n",
    "# 1. Import and create model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 2. Fit the model\n",
    "model.fit(coffee_cups, papers)\n",
    "\n",
    "# 3. Make predictions\n",
    "predictions = model.predict(coffee_cups)\n",
    "\n",
    "# 4. Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(coffee_cups, papers, color='red', s=100, alpha=0.7, label='PhD Students')\n",
    "plt.plot(coffee_cups, predictions, color='blue', linewidth=2, label='Prediction Line')\n",
    "plt.xlabel('☕ Coffee Cups per Day')\n",
    "plt.ylabel('📄 Papers Published')\n",
    "plt.title('The PhD Coffee-Paper Hypothesis\\n(Correlation ≠ Causation!)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Model insights\n",
    "print(f\"📊 Model Results:\")\n",
    "print(f\"   Slope (β₁): {model.coef_[0]:.3f} papers per cup\")\n",
    "print(f\"   Intercept (β₀): {model.intercept_:.3f} baseline papers\")\n",
    "print(f\"   R² Score: {model.score(coffee_cups, papers):.3f}\")\n",
    "print(f\"\\n🤔 Interpretation: Each additional cup of coffee is associated with {model.coef_[0]:.3f} more papers!\")\n",
    "print(f\"   (But remember: correlation ≠ causation. Maybe productive students just drink more coffee?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Load Our Real Data! 📊\n",
    "\n",
    "Time to work with our actual PhD student dataset. Let's load the clean data we created in Block 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our clean dataset\n",
    "df = pd.read_csv('phd_research_productivity_clean.csv')\n",
    "\n",
    "print(f\"🎯 Dataset loaded: {df.shape[0]} PhD students, {df.shape[1]} features\")\n",
    "print(f\"📋 Columns: {list(df.columns)}\")\n",
    "\n",
    "# Quick sanity check\n",
    "print(f\"\\n🔍 Quick check:\")\n",
    "print(f\"   Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"   Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"   ✅ Data looks clean!\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n👀 First 5 students:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Our Machine Learning Problem\n",
    "\n",
    "**Our Goal**: Predict how many papers a PhD student will publish based on their characteristics and behaviors.\n",
    "\n",
    "**Target Variable (y)**: `papers_published` - This is what we want to predict\n",
    "\n",
    "**Features (X)**: Everything else that might influence research productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine our target variable\n",
    "target = 'papers_published'\n",
    "\n",
    "print(f\"🎯 Target Variable: {target}\")\n",
    "print(f\"   Range: {df[target].min()} to {df[target].max()} papers\")\n",
    "print(f\"   Mean: {df[target].mean():.2f} papers\")\n",
    "print(f\"   Median: {df[target].median():.2f} papers\")\n",
    "print(f\"   Std Dev: {df[target].std():.2f} papers\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df[target], bins=range(0, df[target].max() + 2), alpha=0.8, color='#6495ED', edgecolor='black', linewidth=0.8)\n",
    "plt.xlabel('Papers Published', fontsize=12)\n",
    "plt.ylabel('Number of Students', fontsize=12)\n",
    "plt.title('Distribution of Research Productivity\\n(Our Target Variable)', fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.xticks(range(0, df[target].max() + 1))\n",
    "\n",
    "# Box plot by department\n",
    "plt.subplot(1, 2, 2)\n",
    "df.boxplot(column=target, by='department', ax=plt.gca(), patch_artist=True,\n",
    "            boxprops=dict(facecolor='#ADD8E6', color='black'),\n",
    "            medianprops=dict(color='red'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            capprops=dict(color='black'))\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.title('Papers Published by Department', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Department', fontsize=12)\n",
    "plt.ylabel('Papers Published', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: What Might Predict Success?\n",
    "\n",
    "Not all features are equally useful for prediction. Let's select the most relevant ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our features\n",
    "# We'll use numerical features for our first model\n",
    "numerical_features = [\n",
    "    'years_in_program',\n",
    "    'conferences_attended',\n",
    "    'coffee_cups_per_day',\n",
    "    'hours_in_hunt_library_per_week',\n",
    "    'advisor_meetings_per_month',\n",
    "    'stress_level',\n",
    "    'funding_amount',\n",
    "    'distance_from_campus_miles'\n",
    "]\n",
    "\n",
    "# If we have engineered features from Block 2, include them\n",
    "if 'productivity_score' in df.columns:\n",
    "    print(\"🛠️  Found engineered features from Block 2!\")\n",
    "    engineered_features = ['productivity_score', 'work_life_balance']\n",
    "    # Remove productivity_score since it's derived from our target\n",
    "    numerical_features.extend(['work_life_balance'])\n",
    "\n",
    "print(f\"📊 Selected Features ({len(numerical_features)} total):\")\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    print(f\"   {i}. {feature}\")\n",
    "\n",
    "# Create feature matrix (X) and target vector (y)\n",
    "X = df[numerical_features]\n",
    "y = df[target]\n",
    "\n",
    "print(f\"\\n🎯 Feature Matrix (X): {X.shape}\")\n",
    "print(f\"🎯 Target Vector (y): {y.shape}\")\n",
    "\n",
    "# Quick look at feature correlations with target\n",
    "correlations = X.corrwith(y).sort_values(ascending=False)\n",
    "print(f\"\\n📈 Feature Correlations with {target}:\")\n",
    "for feature, corr in correlations.items():\n",
    "    direction = \"📈\" if corr > 0 else \"📉\"\n",
    "    strength = \"Strong\" if abs(corr) > 0.5 else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "    print(f\"   {direction} {feature}: {corr:.3f} ({strength})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Train-Test Split: The Foundation of Honest Evaluation\n",
    "\n",
    "**Golden Rule**: Never test your model on the same data you used to train it!\n",
    "\n",
    "Think of it like studying for an exam:\n",
    "- **Training Set**: Practice problems you use to learn\n",
    "- **Test Set**: The actual exam questions (unseen during study)\n",
    "\n",
    "If you memorize the practice problems, you might ace the practice but fail the real exam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,  # for reproducibility\n",
    "    stratify=None  # what the stratify parameter does is ensure that the distribution of the target variable is similar in both training and test sets.\n",
    "    # Hint: run this cell as is and then try again with stratify=df['department'] to see the difference\n",
    ")\n",
    "\n",
    "print(f\"📊 Data Split Summary:\")\n",
    "print(f\"   Training Set: {X_train.shape[0]} students ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"   Test Set: {X_test.shape[0]} students ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Check that our splits are reasonable\n",
    "print(f\"\\n🔍 Split Quality Check:\")\n",
    "print(f\"   Training target mean: {y_train.mean():.2f} papers\")\n",
    "print(f\"   Test target mean: {y_test.mean():.2f} papers\")\n",
    "print(f\"   Difference: {abs(y_train.mean() - y_test.mean()):.2f} papers\")\n",
    "\n",
    "if abs(y_train.mean() - y_test.mean()) < 0.5:\n",
    "    print(f\"   ✅ Split looks good! Similar distributions.\")\n",
    "else:\n",
    "    print(f\"   ⚠️  Split might be unbalanced. Consider stratification.\")\n",
    "\n",
    "# Visualize the split\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train, bins=15, alpha=0.7, color='blue', label='Training Set')\n",
    "plt.hist(y_test, bins=15, alpha=0.7, color='red', label='Test Set')\n",
    "plt.xlabel('Papers Published')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.title('Target Distribution: Train vs Test')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(range(len(y_train)), sorted(y_train), alpha=0.6, color='blue', label='Training Set')\n",
    "plt.scatter(range(len(y_test)), sorted(y_test), alpha=0.6, color='red', label='Test Set')\n",
    "plt.xlabel('Student Index (sorted)')\n",
    "plt.ylabel('Papers Published')\n",
    "plt.title('Value Distribution Check')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Building Our First Real Model! 🏗️\n",
    "\n",
    "Time to build a model that can predict PhD research productivity based on student characteristics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train our linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to our training data\n",
    "print(\"🏗️  Training the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"✅ Model training complete!\")\n",
    "\n",
    "# Make predictions on both training and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"\\n🎯 Model Performance Summary:\")\n",
    "print(f\"   Training R² Score: {model.score(X_train, y_train):.3f}\")\n",
    "print(f\"   Test R² Score: {model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# The R² score tells us how much of the variance in papers published\n",
    "# our model can explain. 1.0 = perfect, 0.0 = useless\n",
    "test_r2 = model.score(X_test, y_test)\n",
    "print(f\"\\n📊 Model Interpretation:\")\n",
    "print(f\"   Our model explains {test_r2*100:.1f}% of the variance in research productivity\")\n",
    "\n",
    "if test_r2 > 0.7:\n",
    "    print(f\"   🎉 Excellent! This model has strong predictive power.\")\n",
    "elif test_r2 > 0.5:\n",
    "    print(f\"   👍 Good! This model captures important patterns.\")\n",
    "elif test_r2 > 0.3:\n",
    "    print(f\"   🤔 Moderate. The model finds some patterns but misses others.\")\n",
    "else:\n",
    "    print(f\"   😐 Weak. The model struggles to predict research productivity.\")\n",
    "\n",
    "# Let's see the model's coefficients\n",
    "print(f\"\\n🔍 Model Coefficients (β values):\")\n",
    "print(f\"   Intercept (β₀): {model.intercept_:.3f} papers\")\n",
    "\n",
    "# Sort features by absolute coefficient value\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': numerical_features,\n",
    "    'coefficient': model.coef_,\n",
    "    'abs_coefficient': np.abs(model.coef_)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\n📈 Feature Importance (ranked by impact):\")\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    direction = \"📈\" if row['coefficient'] > 0 else \"📉\"\n",
    "    print(f\"   {direction} {row['feature']}: {row['coefficient']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation: What Do These Coefficients Mean?\n",
    "\n",
    "Each coefficient tells us how much the target variable (papers published) changes when that feature increases by 1 unit, **holding all other features constant**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's interpret our coefficients in plain English\n",
    "print(\"🎓 PhD Student Success Insights:\")\n",
    "print(\"   (Based on our linear regression model)\\n\")\n",
    "\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    feature = row['feature']\n",
    "    coef = row['coefficient']\n",
    "    \n",
    "    if feature == 'years_in_program':\n",
    "        print(f\"📅 Experience: Each additional year → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('More experience helps!' if coef > 0 else 'Diminishing returns over time?')}\")\n",
    "    \n",
    "    elif feature == 'coffee_cups_per_day':\n",
    "        print(f\"☕ Coffee: Each additional cup → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('Fuel for productivity!' if coef > 0 else 'Maybe too much coffee causes jitters?')}\")\n",
    "    \n",
    "    elif feature == 'hours_in_hunt_library_per_week':\n",
    "        print(f\"📚 Hunt Library: Each additional hour → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('Time in library pays off!' if coef > 0 else 'Quality over quantity?')}\")\n",
    "    \n",
    "    elif feature == 'advisor_meetings_per_month':\n",
    "        print(f\"👥 Advisor Meetings: Each additional meeting → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('Guidance matters!' if coef > 0 else 'Too many meetings = less research time?')}\")\n",
    "    \n",
    "    elif feature == 'stress_level':\n",
    "        print(f\"😰 Stress Level: Each stress unit → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('Some stress motivates!' if coef > 0 else 'Stress hurts productivity!')}\")\n",
    "    \n",
    "    elif feature == 'funding_amount':\n",
    "        print(f\"💰 Funding: Each additional $1000 → {coef*1000:.3f} more papers\")\n",
    "        print(f\"   💡 {('Money helps research!' if coef > 0 else 'Funding pressure?')}\")\n",
    "    \n",
    "    elif feature == 'conferences_attended':\n",
    "        print(f\"🎤 Conferences: Each additional conference → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('Networking and exposure help!' if coef > 0 else 'Time away from research?')}\")\n",
    "    \n",
    "    elif feature == 'distance_from_campus_miles':\n",
    "        print(f\"🏠 Distance: Each additional mile → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('Remote work benefits?' if coef > 0 else 'Commute time hurts!')}\")\n",
    "    \n",
    "    elif feature == 'work_life_balance':\n",
    "        print(f\"⚖️  Work-Life Balance: Each balance unit → {coef:.3f} more papers\")\n",
    "        print(f\"   💡 {('Balance boosts productivity!' if coef > 0 else 'All work, no play?')}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"⚠️  Remember: These are correlations, not causations!\")\n",
    "print(\"   The model finds patterns but doesn't prove what causes what.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Model Performance\n",
    "\n",
    "Let's see how well our model predicts compared to actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted (Test Set)\n",
    "axes[0, 0].scatter(y_test, y_test_pred, alpha=0.6, color='red', s=60)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Papers Published')\n",
    "axes[0, 0].set_ylabel('Predicted Papers Published')\n",
    "axes[0, 0].set_title('Actual vs Predicted (Test Set)\\nPoints on diagonal = Perfect predictions')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add R² to the plot\n",
    "axes[0, 0].text(0.05, 0.95, f'R² = {model.score(X_test, y_test):.3f}', \n",
    "                transform=axes[0, 0].transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 2. Residuals Plot (Test Set)\n",
    "residuals = y_test - y_test_pred\n",
    "axes[0, 1].scatter(y_test_pred, residuals, alpha=0.6, color='blue', s=60)\n",
    "axes[0, 1].axhline(y=0, color='k', linestyle='--')\n",
    "axes[0, 1].set_xlabel('Predicted Papers Published')\n",
    "axes[0, 1].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[0, 1].set_title('Residuals Plot (Test Set)\\nRandom scatter = Good model')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance\n",
    "feature_importance_plot = feature_importance.head(8)  # Top 8 features\n",
    "colors = ['green' if x > 0 else 'red' for x in feature_importance_plot['coefficient']]\n",
    "bars = axes[1, 0].barh(range(len(feature_importance_plot)), feature_importance_plot['coefficient'], color=colors, alpha=0.7)\n",
    "axes[1, 0].set_yticks(range(len(feature_importance_plot)))\n",
    "axes[1, 0].set_yticklabels([f.replace('_', ' ').title() for f in feature_importance_plot['feature']])\n",
    "axes[1, 0].set_xlabel('Coefficient Value')\n",
    "axes[1, 0].set_title('Feature Importance\\n(Green = Positive, Red = Negative)')\n",
    "axes[1, 0].axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction Distribution\n",
    "all_values = np.concatenate([y_test, y_test_pred])\n",
    "\n",
    "desired_plot_start_label = -1\n",
    "desired_plot_end_label = 9\n",
    "\n",
    "bins = np.arange(desired_plot_start_label - 0.5, desired_plot_end_label + 0.5 + 0.001, 1)\n",
    "\n",
    "axes[1, 1].hist(y_test, bins=bins, alpha=0.7, color='blue', label='Actual', density=True, align='mid')\n",
    "axes[1, 1].hist(y_test_pred, bins=bins, alpha=0.7, color='red', label='Predicted', density=True, align='mid')\n",
    "axes[1, 1].set_xlabel('Papers Published')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].set_title('Distribution: Actual vs Predicted')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].set_xticks(range(desired_plot_start_label, desired_plot_end_label + 1))\n",
    "\n",
    "axes[1, 1].set_xlim(desired_plot_start_label - 0.5, desired_plot_end_label + 0.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Plot Interpretation Guide:\")\n",
    "print(\"   🎯 Top-left: Points close to diagonal = accurate predictions\")\n",
    "print(\"   🎯 Top-right: Random scatter around 0 = good model (no patterns in errors)\")\n",
    "print(\"   🎯 Bottom-left: Longer bars = more important features\")\n",
    "print(\"   🎯 Bottom-right: Similar shapes = model captures data distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Model Evaluation - How Good Is Our Model? 📏\n",
    "\n",
    "R² is just one metric. Let's evaluate our model comprehensively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate multiple evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, dataset_name):\n",
    "    \"\"\"Calculate and display comprehensive model evaluation metrics\"\"\"\n",
    "    \n",
    "    # Regression metrics\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Additional metrics\n",
    "    mean_target = np.mean(y_true)\n",
    "    mae_baseline = np.mean(np.abs(y_true - mean_target))  # Always predicting mean\n",
    "    improvement = (mae_baseline - mae) / mae_baseline * 100\n",
    "    \n",
    "    print(f\"📊 {dataset_name} Set Performance:\")\n",
    "    print(f\"   R² Score: {r2:.4f} ({r2*100:.1f}% of variance explained)\")\n",
    "    print(f\"   Mean Absolute Error: {mae:.3f} papers\")\n",
    "    print(f\"   Root Mean Squared Error: {rmse:.3f} papers\")\n",
    "    print(f\"   Mean Squared Error: {mse:.3f} papers²\")\n",
    "    print(f\"   Improvement over baseline: {improvement:.1f}%\")\n",
    "    \n",
    "    # Interpret the metrics\n",
    "    print(f\"\\n🎯 What this means:\")\n",
    "    print(f\"   On average, our predictions are off by {mae:.2f} papers\")\n",
    "    print(f\"   Our model is {improvement:.1f}% better than just guessing the average\")\n",
    "    \n",
    "    if r2 > 0.8:\n",
    "        print(f\"   🎉 Excellent model! Very strong predictive power.\")\n",
    "    elif r2 > 0.6:\n",
    "        print(f\"   👍 Good model! Captures most important patterns.\")\n",
    "    elif r2 > 0.4:\n",
    "        print(f\"   🤔 Moderate model. Useful but room for improvement.\")\n",
    "    else:\n",
    "        print(f\"   😐 Weak model. Consider more features or different approach.\")\n",
    "    \n",
    "    return r2, mae, rmse\n",
    "\n",
    "# Evaluate on both training and test sets\n",
    "print(\"🏋️ Model Evaluation Results:\\n\")\n",
    "train_r2, train_mae, train_rmse = evaluate_model(y_train, y_train_pred, \"Training\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "test_r2, test_mae, test_rmse = evaluate_model(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Check for overfitting\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🔍 Overfitting Check:\")\n",
    "r2_diff = train_r2 - test_r2\n",
    "mae_diff = test_mae - train_mae\n",
    "\n",
    "print(f\"   Training R²: {train_r2:.4f}\")\n",
    "print(f\"   Test R²: {test_r2:.4f}\")\n",
    "print(f\"   Difference: {r2_diff:.4f}\")\n",
    "\n",
    "if r2_diff < 0.05:\n",
    "    print(f\"   ✅ No overfitting detected! Model generalizes well.\")\n",
    "elif r2_diff < 0.15:\n",
    "    print(f\"   ⚠️  Mild overfitting. Model performs slightly worse on new data.\")\n",
    "else:\n",
    "    print(f\"   🚨 Significant overfitting! Model memorized training data.\")\n",
    "\n",
    "# Context for PhD students\n",
    "print(f\"\\n🎓 PhD Context:\")\n",
    "print(f\"   Average PhD student publishes {np.mean(y):.1f} papers\")\n",
    "print(f\"   Our model's average error is {test_mae:.2f} papers\")\n",
    "print(f\"   That's {test_mae/np.mean(y)*100:.1f}% of the average - pretty good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: The Gold Standard\n",
    "\n",
    "One train-test split gives us one estimate. **Cross-validation** gives us multiple estimates for more robust evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "cv_mae_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "cv_mae_scores = -cv_mae_scores  # Convert back to positive\n",
    "\n",
    "print(\"🔄 5-Fold Cross-Validation Results:\")\n",
    "print(f\"   R² Scores: {cv_scores}\")\n",
    "print(f\"   Mean R²: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "print(f\"   MAE Scores: {cv_mae_scores}\")\n",
    "print(f\"   Mean MAE: {cv_mae_scores.mean():.3f} (±{cv_mae_scores.std():.3f})\")\n",
    "\n",
    "# Visualize cross-validation results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# R² scores\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot([cv_scores], tick_labels=['Cross-Validation'])\n",
    "plt.scatter([1], [test_r2], color='red', s=100, label='Single Test Split')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Cross-Validation R² Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# MAE scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([cv_mae_scores], tick_labels=['Cross-Validation'])\n",
    "plt.scatter([1], [test_mae], color='red', s=100, label='Single Test Split')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Cross-Validation MAE Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n📊 Cross-Validation Insights:\")\n",
    "print(f\"   Our model consistently achieves R² between {cv_scores.min():.3f} and {cv_scores.max():.3f}\")\n",
    "print(f\"   Standard deviation of {cv_scores.std():.4f} indicates {'consistent' if cv_scores.std() < 0.1 else 'variable'} performance\")\n",
    "print(f\"   The single test split result ({test_r2:.4f}) is {'within' if abs(test_r2 - cv_scores.mean()) < cv_scores.std() else 'outside'} the typical range\")\n",
    "\n",
    "# Compare with our single split\n",
    "if abs(test_r2 - cv_scores.mean()) < cv_scores.std():\n",
    "    print(f\"   ✅ Our single split gives a representative estimate!\")\n",
    "else:\n",
    "    print(f\"   ⚠️  Our single split might be optimistic or pessimistic. Trust the CV average.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Hands-On Exercise: Make Your Own Predictions!\n",
    "\n",
    "Let's use our model to predict research productivity for hypothetical PhD students:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hypothetical PhD student profiles\n",
    "hypothetical_students = pd.DataFrame({\n",
    "    'Student': ['The Newbie', 'The Veteran', 'The Coffee Addict', 'The Balanced One', 'The Workaholic'],\n",
    "    'years_in_program': [1, 6, 3, 4, 5],\n",
    "    'conferences_attended': [0, 8, 2, 4, 3],\n",
    "    'coffee_cups_per_day': [2, 4, 8, 3, 5],\n",
    "    'hours_in_hunt_library_per_week': [20, 30, 25, 35, 50],\n",
    "    'advisor_meetings_per_month': [2, 3, 4, 4, 2],\n",
    "    'stress_level': [3, 6, 7, 5, 8],\n",
    "    'funding_amount': [25000, 32000, 28000, 30000, 35000],\n",
    "    'distance_from_campus_miles': [2, 5, 1, 3, 10]\n",
    "})\n",
    "\n",
    "# Add work_life_balance if it exists in our features\n",
    "if 'work_life_balance' in numerical_features:\n",
    "    hypothetical_students['work_life_balance'] = [8, 6, 4, 8, 3]\n",
    "\n",
    "# Make predictions\n",
    "student_features = hypothetical_students[numerical_features]\n",
    "predictions = model.predict(student_features)\n",
    "\n",
    "# Display results\n",
    "print(\"🎯 Hypothetical PhD Student Predictions:\\n\")\n",
    "\n",
    "for i, (idx, student) in enumerate(hypothetical_students.iterrows()):\n",
    "    pred = predictions[i]\n",
    "    print(f\"👤 {student['Student']}:\")\n",
    "    print(f\"   Profile: {student['years_in_program']} years, {student['coffee_cups_per_day']} cups/day, {student['hours_in_hunt_library_per_week']} hrs/week in Hunt\")\n",
    "    print(f\"   Predicted papers: {pred:.2f}\")\n",
    "    \n",
    "    # Add some personality to the predictions\n",
    "    if pred > 4:\n",
    "        print(f\"   🌟 High achiever! Well above average.\")\n",
    "    elif pred > 2:\n",
    "        print(f\"   👍 Solid performance! Right on track.\")\n",
    "    else:\n",
    "        print(f\"   🌱 Room for growth. Consider the high-impact factors!\")\n",
    "    print()\n",
    "\n",
    "# Let's also show what factors would most help \"The Newbie\"\n",
    "print(\"💡 Advice for 'The Newbie' (based on our model):\")\n",
    "newbie_idx = 0\n",
    "current_pred = predictions[newbie_idx]\n",
    "\n",
    "# Test impact of changing key factors\n",
    "advice_scenarios = {\n",
    "    'Double coffee intake': student_features.copy(),\n",
    "    'Attend 2 conferences': student_features.copy(),\n",
    "    'Increase Hunt Library time': student_features.copy(),\n",
    "    'More advisor meetings': student_features.copy()\n",
    "}\n",
    "\n",
    "advice_scenarios['Double coffee intake'].iloc[newbie_idx, advice_scenarios['Double coffee intake'].columns.get_loc('coffee_cups_per_day')] *= 2\n",
    "advice_scenarios['Attend 2 conferences'].iloc[newbie_idx, advice_scenarios['Attend 2 conferences'].columns.get_loc('conferences_attended')] += 2\n",
    "advice_scenarios['Increase Hunt Library time'].iloc[newbie_idx, advice_scenarios['Increase Hunt Library time'].columns.get_loc('hours_in_hunt_library_per_week')] += 15\n",
    "advice_scenarios['More advisor meetings'].iloc[newbie_idx, advice_scenarios['More advisor meetings'].columns.get_loc('advisor_meetings_per_month')] += 2\n",
    "\n",
    "for scenario, data in advice_scenarios.items():\n",
    "    new_pred = model.predict(data)[newbie_idx]\n",
    "    impact = new_pred - current_pred\n",
    "    print(f\"   {scenario}: {impact:+.3f} papers ({impact/current_pred*100:+.1f}%)\")\n",
    "\n",
    "print(f\"\\n💭 Remember: These are model predictions, not guarantees!\")\n",
    "print(f\"   Focus on sustainable habits and genuine learning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤔 Your Turn: Create Your Own Student Profile!\n",
    "\n",
    "Design a hypothetical PhD student and see what our model predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create your own hypothetical PhD student profile\n",
    "# Fill in the values below and run the cell to see the prediction!\n",
    "\n",
    "my_student = {\n",
    "    'years_in_program': ???,  # Change this: 1-7 years\n",
    "    'conferences_attended': ???,  # Change this: 0-10 conferences\n",
    "    'coffee_cups_per_day': ???,  # Change this: 0-8 cups\n",
    "    'hours_in_hunt_library_per_week': ???,  # Change this: 0-60 hours\n",
    "    'advisor_meetings_per_month': ???,  # Change this: 1-8 meetings\n",
    "    'stress_level': ???,  # Change this: 1-10 stress level\n",
    "    'funding_amount': ???,  # Change this: 20000-40000 dollars\n",
    "    'distance_from_campus_miles': ???,  # Change this: 0-20 miles\n",
    "}\n",
    "\n",
    "# Add work_life_balance if it exists\n",
    "if 'work_life_balance' in numerical_features:\n",
    "    my_student['work_life_balance'] = ???  # Change this: 1-10 balance score\n",
    "\n",
    "# Convert to DataFrame and make prediction\n",
    "my_student_df = pd.DataFrame([my_student])\n",
    "my_prediction = model.predict(my_student_df[numerical_features])[0]\n",
    "\n",
    "print(f\"🎓 Your PhD Student Profile:\")\n",
    "for key, value in my_student.items():\n",
    "    print(f\"   {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(f\"\\n🎯 Model Prediction: {my_prediction:.2f} papers\")\n",
    "\n",
    "# Compare to dataset averages\n",
    "avg_papers = y.mean()\n",
    "percentile = (y <= my_prediction).mean() * 100\n",
    "\n",
    "print(f\"\\n📊 Comparison:\")\n",
    "print(f\"   Dataset average: {avg_papers:.2f} papers\")\n",
    "print(f\"   Your student: {my_prediction:.2f} papers\")\n",
    "print(f\"   Performance: {my_prediction/avg_papers*100:.1f}% of average\")\n",
    "print(f\"   Percentile: {percentile:.1f}th percentile\")\n",
    "\n",
    "if my_prediction > avg_papers * 1.2:\n",
    "    print(f\"   🌟 Excellent! This student is highly productive!\")\n",
    "elif my_prediction > avg_papers:\n",
    "    print(f\"   👍 Good! Above average performance.\")\n",
    "elif my_prediction > avg_papers * 0.8:\n",
    "    print(f\"   🤔 Average performance. Room for improvement.\")\n",
    "else:\n",
    "    print(f\"   📈 Below average. Consider focusing on high-impact factors.\")\n",
    "\n",
    "print(f\"\\n💡 Try changing the values above and re-running to see how different factors affect productivity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Advanced Model Analysis (Optional Deep Dive) 🔬\n",
    "\n",
    "For those who want to go deeper into model analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling: Does It Matter?\n",
    "\n",
    "Linear regression doesn't require feature scaling, but it can help with interpretation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models with and without scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train scaled model\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compare performance\n",
    "r2_original = model.score(X_test, y_test)\n",
    "r2_scaled = model_scaled.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"🔄 Feature Scaling Comparison:\")\n",
    "print(f\"   Original model R²: {r2_original:.4f}\")\n",
    "print(f\"   Scaled model R²: {r2_scaled:.4f}\")\n",
    "print(f\"   Difference: {abs(r2_original - r2_scaled):.6f}\")\n",
    "\n",
    "if abs(r2_original - r2_scaled) < 0.001:\n",
    "    print(f\"   ✅ Scaling doesn't change performance (as expected for linear regression)\")\n",
    "else:\n",
    "    print(f\"   ⚠️  Unexpected difference - check for numerical issues\")\n",
    "\n",
    "# Compare coefficient interpretability\n",
    "print(f\"\\n📊 Coefficient Comparison (Scaled vs Original):\")\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Original': model.coef_,\n",
    "    'Scaled': model_scaled.coef_\n",
    "})\n",
    "\n",
    "print(f\"   With scaling, coefficients represent the change in papers per standard deviation change in feature\")\n",
    "print(f\"   Larger absolute values = more important features\")\n",
    "print(coef_comparison.sort_values('Scaled', key=abs, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assumptions Check\n",
    "\n",
    "Linear regression makes several assumptions. Let's check them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check linear regression assumptions\n",
    "# Assuming 'y_test_pred' and 'residuals' are already calculated from your scikit-learn model\n",
    "# For example: model.fit(X_train, y_train) and y_test_pred = model.predict(X_test)\n",
    "# residuals = y_test - y_test_pred\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Linearity: Residuals vs Fitted\n",
    "axes[0, 0].scatter(y_test_pred, residuals, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Fitted Values')\n",
    "axes[0, 0].set_ylabel('Residuals')\n",
    "axes[0, 0].set_title('Linearity Check\\n(Should be random scatter around 0)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Normality: Q-Q plot of residuals\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "axes[0, 1].set_title('Normality Check\\n(Should follow diagonal line)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Homoscedasticity: Scale-Location plot with LOWESS line\n",
    "import statsmodels.api as sm\n",
    "sqrt_abs_resid = np.sqrt(np.abs(residuals))\n",
    "axes[1, 0].scatter(y_test_pred, sqrt_abs_resid, alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Fitted Values')\n",
    "axes[1, 0].set_ylabel('√|Residuals|')\n",
    "axes[1, 0].set_title('Homoscedasticity Check\\n(Trend line should be flat and horizontal)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Lowess line to visualize the trend\n",
    "lowess = sm.nonparametric.lowess(sqrt_abs_resid, y_test_pred, frac=0.6)\n",
    "axes[1, 0].plot(lowess[:, 0], lowess[:, 1], color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# 4. Independence: Residuals histogram\n",
    "axes[1, 1].hist(residuals, bins=20, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Residuals')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Residual Distribution\\n(Should be approximately normal)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests\n",
    "print(f\"📊 Assumption Check Summary for scikit-learn LinearRegression model:\")\n",
    "\n",
    "# Test normality with Shapiro-Wilk\n",
    "shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "print(f\"   Normality (Shapiro-Wilk): p-value = {shapiro_p:.6f}\")\n",
    "if shapiro_p > 0.05:\n",
    "    print(f\"   ✅ Residuals appear normally distributed\")\n",
    "else:\n",
    "    print(f\"   ⚠️  Residuals may not be normally distributed\")\n",
    "\n",
    "# Test homoscedasticity with Breusch-Pagan test\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "# The test requires the full feature set (X_test) and the residuals\n",
    "# We add a constant to X_test to match statsmodels's requirements\n",
    "X_test_with_const = sm.add_constant(X_test)\n",
    "\n",
    "# Breusch-Pagan test returns: Lagrange Multiplier stat, p-value, F-stat, F-p-value\n",
    "bp_test = het_breuschpagan(residuals, X_test_with_const)\n",
    "\n",
    "print(f\"   Homoscedasticity (Breusch-Pagan): p-value = {bp_test[1]:.6f}\")\n",
    "if bp_test[1] > 0.05:\n",
    "    print(\"   ✅ The residuals appear to have constant variance (homoscedastic)\")\n",
    "else:\n",
    "    print(\"   ⚠️  The residuals show non-constant variance (heteroscedastic)\")\n",
    "\n",
    "print(f\"\\n💡 What violations mean:\")\n",
    "print(f\"   - Non-linearity: Consider polynomial features or a different model\")\n",
    "print(f\"   - Non-normality: Predictions still valid, but confidence intervals may be off\")\n",
    "print(f\"   - Heteroscedasticity: Standard errors may be incorrect. Consider robust standard errors or a transformation.\")\n",
    "print(f\"   - Non-independence: Need to account for data structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Confidence and Prediction Intervals\n",
    "\n",
    "Linear regression can provide uncertainty estimates for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction intervals (approximate method)\n",
    "# For a more precise method, you'd need to use statistical libraries\n",
    "\n",
    "# Calculate residual standard error\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "residual_se = np.sqrt(mse)\n",
    "\n",
    "# Approximate 95% prediction intervals\n",
    "# This is a simplified approach - actual calculation is more complex\n",
    "confidence_level = 0.95\n",
    "z_score = stats.norm.ppf((1 + confidence_level) / 2)\n",
    "prediction_interval = z_score * residual_se\n",
    "\n",
    "print(f\"📊 Model Uncertainty Analysis:\")\n",
    "print(f\"   Residual Standard Error: {residual_se:.3f} papers\")\n",
    "print(f\"   Approximate 95% Prediction Interval: ±{prediction_interval:.3f} papers\")\n",
    "print(f\"   This means roughly 95% of predictions should be within ±{prediction_interval:.3f} papers of actual values\")\n",
    "\n",
    "# Test this claim\n",
    "within_interval = np.abs(residuals) <= prediction_interval\n",
    "actual_coverage = np.mean(within_interval) * 100\n",
    "\n",
    "print(f\"\\n🎯 Actual Coverage: {actual_coverage:.1f}% of predictions within interval\")\n",
    "print(f\"   Expected: ~95%\")\n",
    "print(f\"   {'✅ Good match!' if 85 <= actual_coverage <= 100 else '⚠️ Coverage differs from expected'}\")\n",
    "\n",
    "# Visualize uncertainty\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.6, label='Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', label='Perfect Prediction')\n",
    "\n",
    "# Add prediction intervals\n",
    "sorted_indices = np.argsort(y_test)\n",
    "y_test_sorted = y_test.iloc[sorted_indices]\n",
    "y_pred_sorted = y_test_pred[sorted_indices]\n",
    "\n",
    "plt.fill_between(y_test_sorted, \n",
    "                y_pred_sorted - prediction_interval,\n",
    "                y_pred_sorted + prediction_interval,\n",
    "                alpha=0.2, color='red', label='95% Prediction Interval')\n",
    "\n",
    "plt.xlabel('Actual Papers Published')\n",
    "plt.ylabel('Predicted Papers Published')\n",
    "plt.title('Model Predictions with Uncertainty')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n💭 Practical Interpretation:\")\n",
    "print(f\"   When we predict a student will publish {y_test.iloc[5]:.1f} papers,\")\n",
    "print(f\"   we're 95% confident the actual value will be between {y_test_pred[5] - prediction_interval:.1f} and {y_test_pred[5] + prediction_interval:.1f} papers\")\n",
    "print(f\"   This uncertainty is important for making decisions based on predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎉 Congratulations! You're Now a Machine Learning Practitioner!\n",
    "\n",
    "## What We've Accomplished\n",
    "\n",
    "In this block, you've learned to:\n",
    "\n",
    "✅ **Understand Machine Learning Fundamentals**\n",
    "- Supervised vs unsupervised learning\n",
    "- Linear regression theory and applications\n",
    "- The scikit-learn workflow\n",
    "\n",
    "✅ **Understand the ML Pipeline**\n",
    "- Load and prepare data for modeling\n",
    "- Split data into training and test sets\n",
    "- Train models and make predictions\n",
    "- Evaluate model performance comprehensively\n",
    "\n",
    "✅ **Evaluate Models Like a Pro**\n",
    "- Multiple metrics: R², MAE, MSE, RMSE\n",
    "- Cross-validation for robust evaluation\n",
    "- Overfitting detection\n",
    "- Model assumption checking\n",
    "\n",
    "✅ **Interpret Results Meaningfully**\n",
    "- Coefficient interpretation\n",
    "- Feature importance analysis\n",
    "- Prediction confidence intervals\n",
    "- Practical implications for PhD success\n",
    "\n",
    "## Key Insights from Our PhD Research Productivity Model\n",
    "\n",
    "Based on our analysis, here are the key factors that predict PhD research productivity:\n",
    "\n",
    "1. **Experience matters**: Years in program strongly correlate with papers published\n",
    "2. **Engagement pays off**: Conference attendance and advisor meetings both help\n",
    "3. **Balance is key**: Both work intensity and work-life balance contribute\n",
    "4. **Individual variation**: Even with good predictors, there's significant individual variation\n",
    "\n",
    "## The Big Picture: What This Means for Your Research\n",
    "\n",
    "🎯 **For Your PhD Journey**:\n",
    "- Focus on consistent, sustainable practices\n",
    "- Engage with the research community (conferences, collaborations)\n",
    "- Maintain regular communication with your advisor\n",
    "- Remember that productivity varies - don't get discouraged!\n",
    "\n",
    "🎯 **For Your Research Skills**:\n",
    "- You now know the full ML pipeline from data to insights\n",
    "- You can build, evaluate, and interpret predictive models\n",
    "- You understand the importance of proper validation\n",
    "- You can make data-driven decisions with confidence\n",
    "\n",
    "## Next Steps: Block 4 Preview 🚀\n",
    "\n",
    "In **Block 4: From Data to Decisions**, we'll explore **optimization modeling** with Pyomo:\n",
    "- Formulate decision problems mathematically\n",
    "- Solve optimization problems with Python\n",
    "- Move from \"what might happen\" (prediction) to \"what should we do\" (optimization)\n",
    "- Apply OR techniques to real problems\n",
    "\n",
    "## 🔧 Advanced Challenges (Optional Homework)\n",
    "\n",
    "If you want to practice more:\n",
    "\n",
    "1. **Try different models**: Import and test `Ridge`, `Lasso`, or `ElasticNet` regression\n",
    "2. **Feature engineering**: Create interaction terms or polynomial features\n",
    "3. **Category encoding**: Include department as a categorical variable\n",
    "4. **Regularization**: Compare models with different regularization strengths\n",
    "5. **Ensemble methods**: Try `RandomForestRegressor` or `GradientBoostingRegressor`\n",
    "\n",
    "## Remember: Models Are Tools, Not Truth\n",
    "\n",
    "Our model found patterns in data, but:\n",
    "- **Correlation ≠ Causation**: High coffee consumption doesn't cause more papers\n",
    "- **Models simplify reality**: Real PhD success depends on many unmeasured factors\n",
    "- **Data has limitations**: Our synthetic data may not reflect all real-world patterns\n",
    "- **Context matters**: Use models to inform decisions, not replace judgment\n",
    "\n",
    "Great work, data scientists! You've mastered the fundamentals of predictive modeling. Now let's go optimize some decisions in Block 4! 🎓✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
